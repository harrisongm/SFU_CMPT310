{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>NOTE</h3>\n",
    "    <p>Before you submit this assignment, <strong>make sure everything runs as expected</strong>:</p>\n",
    "    <ol>\n",
    "        <li><strong>restart the kernel</strong> (in the menubar, select <strong>Kernel → Restart</strong>)\n",
    "        <li><strong>run all cells</strong> (in the menubar, select <strong>Cell → Run All</strong>)</li>\n",
    "    </ol>\n",
    "    <p>Make sure to complete every cell that states \"<strong><TT>YOUR CODE IN THIS CELL</TT></strong>\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #2\n",
    "\n",
    "<font color=red>**Due**:<font color=black> Sat Mar 4 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**NOTE:**<font color=black> These questions are intended to get your feet wet in the spectrum and **breadth** of open research problems in NLP. They are *not* intended for you to explore a problem in any **depth**.\n",
    "\n",
    "For the coding questions, aim to have a simple, working prototype that you could revisit at a later time if you wanted to improve its performance.\n",
    "    \n",
    "A \"best practice\" is to work these out *by hand* first to know what is reasonable for your code to be able to do (knowing it can be done by a human). An example is identifying whether the word `run` is a verb or not. Can you determine whther `run` is a verb?\n",
    "    \n",
    "Note that some of the tasks in this assignment could be considered a Master's Thesis (if not a PhD thesis)! Do not get frustrated or overwhelmed by the difficulty of each problem.\n",
    "    \n",
    "Feel free to work with others but make sure you are submitting your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<font color=blue>\n",
    "    \n",
    "#### OBJECTIVES\n",
    "    \n",
    "<font color=black>\n",
    "\n",
    "* become familiar with the `JupyterLab Notebook` format for the assignments\n",
    "* embrace failure\n",
    "* learn from failure, don't just give up when something doesn't work\n",
    "* get your feet wet in seemingly simple text processing problems\n",
    "* become familiar with `NLTK`\n",
    "* encounter a variety of open problems in natural language processing *prior* to studying them formally (in order to motivate their formal study)\n",
    "* practice the workflow that will be used throughout this course: gather data, implement code, evaluate code, discuss\n",
    "* emphasize the **discussion** and **reflection** aspect of computing science/research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<font color=darkred>\n",
    "    \n",
    "# Preparation: NLTK Natural Language Toolkit\n",
    "\n",
    "<font color=black>\n",
    "\n",
    "**NLTK** stands for **Natural Language Toolkit**. It is written in **Python** and intended to be fairly easy to pick up.\n",
    "    \n",
    "The **NLTK book** is found here: https://www.nltk.org/book\n",
    "\n",
    "In order to complete this assignment you must complete Chapters #1, #2, and #3. It is recommended you not just read through the examples but create a **Jupyter Notebook** where you are typing the various commands as you go.\n",
    "\n",
    "A few of your other assignments will use **NLTK** as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<font color=darkred>\n",
    "    \n",
    "# Question: Tokenizing Text\n",
    "\n",
    "<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will process text saved to the `text_data` variable. The variable is of type `String`.\n",
    "\n",
    "This data is know as a (very small) **dataset**, or sometimes referred to as **corpora**.\n",
    "The etymology of <font color=darkred>**corpora**<font color=black> is it comes from **corpus** or **corpse**, meaning the body of something. So **corpora** refers to a **body of texts** (or collection of texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"\"\"\n",
    "Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think\n",
    "that they can change the world, are the ones who do.\n",
    "The quote baove is by Steve Jobs. Mr. Jobs also said: I choose a lazy person to do a hard job. Because a lazy person will find an easy way to do it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the above text into **paragraph tokens** (a list of paragraphs).\\\n",
    "How many paragraphs do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "paragraphs = text_data.split('\\n\\n')\n",
    "\n",
    "number_of_paragraphs = len(paragraphs)\n",
    "print(number_of_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the above text into **sentence tokens**.\\\n",
    "How many sentences do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "\n",
    "sentences = []\n",
    "for paragraph in paragraphs:\n",
    "    # replace \\n with \" \"\n",
    "    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "    sentences += paragraph.split('.')\n",
    "\n",
    "number_of_sentences = len(sentences)\n",
    "print(number_of_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the above text into **word tokens**.\\\n",
    "How many words do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "words = []\n",
    "for sentence in sentences:\n",
    "    # split words based on \" \"\n",
    "    temp = sentence.split(\" \")\n",
    "    # remove empty string\n",
    "    temp.remove(\"\")\n",
    "    words += temp\n",
    "words.remove(\"\")\n",
    "\n",
    "number_of_words = len(words)\n",
    "print(number_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<font color=darkred>\n",
    "    \n",
    "# Gathering Results: Frequency Distributions\n",
    "    \n",
    "<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine what the most frequent words in the `text_data` variable are. List the top 20 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 12), ('to', 4), ('do', 4), ('crazy', 3), ('ones', 3), ('who', 3), ('see', 3), ('them,', 3), ('a', 3), ('ones,', 2), ('The', 2), ('things', 2), ('can', 2), ('quote', 2), ('is', 2), ('them', 2), ('because', 2), ('they', 2), ('change', 2), ('are', 2)]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "\n",
    "# get word frequency\n",
    "word_frequency = {}\n",
    "for word  in words:\n",
    "    if word not in word_frequency:\n",
    "        word_frequency[word] = 1\n",
    "    else:\n",
    "        word_frequency[word] += 1\n",
    "\n",
    "word_frequency = sorted(word_frequency.items(), key=lambda x:x[1], reverse=True)\n",
    "print(word_frequency[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here’s',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones,',\n",
       " 'the',\n",
       " 'misfits,',\n",
       " 'the',\n",
       " 'rebels,',\n",
       " 'the',\n",
       " 'troublemakers,',\n",
       " 'the',\n",
       " 'round',\n",
       " 'pegs',\n",
       " 'in',\n",
       " 'the',\n",
       " 'square',\n",
       " 'holes',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'see',\n",
       " 'things',\n",
       " 'differently',\n",
       " '—',\n",
       " 'they’re',\n",
       " 'not',\n",
       " 'fond',\n",
       " 'of',\n",
       " 'rules',\n",
       " 'You',\n",
       " 'can',\n",
       " 'quote',\n",
       " 'them,',\n",
       " 'disagree',\n",
       " 'with',\n",
       " 'them,',\n",
       " 'glorify',\n",
       " 'or',\n",
       " 'vilify',\n",
       " 'them,',\n",
       " 'but',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'you',\n",
       " 'can’t',\n",
       " 'do',\n",
       " 'is',\n",
       " 'ignore',\n",
       " 'them',\n",
       " 'because',\n",
       " 'they',\n",
       " 'change',\n",
       " 'things',\n",
       " 'They',\n",
       " 'push',\n",
       " 'the',\n",
       " 'human',\n",
       " 'race',\n",
       " 'forward,',\n",
       " 'and',\n",
       " 'while',\n",
       " 'some',\n",
       " 'may',\n",
       " 'see',\n",
       " 'them',\n",
       " 'as',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones,',\n",
       " 'we',\n",
       " 'see',\n",
       " 'genius,',\n",
       " 'because',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'are',\n",
       " 'crazy',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'think',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world,',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'do',\n",
       " 'The',\n",
       " 'quote',\n",
       " 'baove',\n",
       " 'is',\n",
       " 'by',\n",
       " 'Steve',\n",
       " 'Jobs',\n",
       " 'Mr',\n",
       " 'Jobs',\n",
       " 'also',\n",
       " 'said:',\n",
       " 'I',\n",
       " 'choose',\n",
       " 'a',\n",
       " 'lazy',\n",
       " 'person',\n",
       " 'to',\n",
       " 'do',\n",
       " 'a',\n",
       " 'hard',\n",
       " 'job',\n",
       " 'Because',\n",
       " 'a',\n",
       " 'lazy',\n",
       " 'person',\n",
       " 'will',\n",
       " 'find',\n",
       " 'an',\n",
       " 'easy',\n",
       " 'way',\n",
       " 'to',\n",
       " 'do',\n",
       " 'it']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<font color=darkred>\n",
    "    \n",
    "# Reflection & Thoughts\n",
    "    \n",
    "<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the following:\n",
    "* how well did your code do at tokenizing the text into words?\n",
    "* how did you evaluate whether it performed well?\n",
    "* is there anything surprising or unusual in your findings/results?\n",
    "* why did you get the results you did?\n",
    "* what can you do better to improve the performance/results?\n",
    "* what appears to potentially provide the biggest boost in performance if you could have taken care of the shortcoming?\n",
    "* how represent is the dataset of text data in general?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenization functionality of my code is relatively accurate in breaking down the text_data into individual words. To evaluate its performance, I compared the tokenized words obtained from my code to the original text_data and found that every word in the text_data was represented in the result. However, one limitation of my code is that it does not tokenize punctuations correctly. Some punctuations are treated as part of a word, while periods are missing altogether.\n",
    "\n",
    "To address this issue, I plan to first clean the text_data by performing case folding and handling abbreviations before tokenizing it with proper consideration of punctuations. This will likely result in a significant improvement in performance.\n",
    "\n",
    "Currently, my code tokenizes the text_data by first breaking it down into paragraphs and then further segmenting them into sentences based on periods. However, this approach causes periods to be omitted from the result. Next, the code loops over all sentences and splits them by spaces to extract the words. Unfortunately, this approach does not handle punctuations well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<font color=#B6321C>\n",
    "    \n",
    "### RUBRIC\n",
    "\n",
    "<font color=black>\n",
    "\n",
    "I will be evaluating this assignment mostly by your attempt to explore and probe the problem (via code or via curiousity). The assignments will build on developing critical thinking and <font color=darkgreen>**asking questions**<font color=black>,  and <font color=darkred>*not coming up with the answers*<font color=black>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A breakdown of the marking for this assignment:\n",
    "* <font color=#B6321C>[**15 marks**]<font color=black> for tokenizing the text:\n",
    "    * <font color=#B6321C>[**5 marks**]<font color=black> for tokenizing paragraphs\n",
    "    * <font color=#B6321C>[**5 marks**]<font color=black> for tokenizing sentences\n",
    "    * <font color=#B6321C>[**5 marks**]<font color=black> for tokenizing words\n",
    "* <font color=#B6321C>[**10 marks**]<font color=black> for presenting the frequency distributions of the top 20 most frequent words\n",
    "* <font color=#B6321C>[**25 marks**]<font color=black> for analysis of the experiment, thoughts about the results acquired, ideas for future work or what could possibly improve the current system's performance, general reflective thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total of this assignment is <font color=#B6321C>[**50 marks**]<font color=black>. It will be scaled to be out of 10 on **Blackboard**.\\\n",
    "Most students will get close to perfect.\n",
    "    \n",
    "If you need help, feel free to email me any questions and/or post your questions to <font color=#B6321C>**Discord**<font color=black>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<font color=darkred>\n",
    "    \n",
    "# QUESTION: Creating Rules To Identify Verbs\n",
    "    \n",
    "<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of **verbs** taken from https://eslgrammar.org/list-of-verbs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Accept\n",
    "Achieve\n",
    "Add\n",
    "Admire\n",
    "Admit\n",
    "Adopt\n",
    "Advise\n",
    "Agree\n",
    "Allow\n",
    "Announce\n",
    "Appreciate\n",
    "Approve\n",
    "Argue\n",
    "Arrive\n",
    "Ask\n",
    "Assist\n",
    "Attack\n",
    "Bake\n",
    "Bathe\n",
    "Be\n",
    "Beat\n",
    "Become\n",
    "Beg\n",
    "Behave\n",
    "Bet\n",
    "Boast\n",
    "Boil\n",
    "Borrow\n",
    "Breathe\n",
    "Bring\n",
    "Build\n",
    "Burn\n",
    "Bury\n",
    "bury\n",
    "Buried\n",
    "Burying\n",
    "Buy\n",
    "Call\n",
    "Catch\n",
    "Challenge\n",
    "Change\n",
    "Cheat\n",
    "Chew\n",
    "Choose\n",
    "Clap\n",
    "Clean\n",
    "Collect\n",
    "Compare\n",
    "Complain\n",
    "Confess\n",
    "Confuse\n",
    "Construct\n",
    "Control\n",
    "Copy\n",
    "Count\n",
    "Create\n",
    "Cry\n",
    "Damage\n",
    "Dance\n",
    "Deliver\n",
    "Destroy\n",
    "Disagree\n",
    "Drag\n",
    "Drive\n",
    "Drop\n",
    "Earn\n",
    "Eat\n",
    "Employ\n",
    "Encourage\n",
    "Enjoy\n",
    "Establish\n",
    "Estimate\n",
    "Exercise\n",
    "Expand\n",
    "Explain\n",
    "Fear\n",
    "Feel\n",
    "Fight\n",
    "Find\n",
    "Fly\n",
    "Forget\n",
    "Forgive\n",
    "Fry\n",
    "Gather\n",
    "Get\n",
    "Give\n",
    "Glow\n",
    "Greet\n",
    "Grow\n",
    "Guess\n",
    "Harass\n",
    "Hate\n",
    "Hear\n",
    "Help\n",
    "Hit\n",
    "Hope\n",
    "Identify\n",
    "Interrupt\n",
    "Introduce\n",
    "Irritate\n",
    "Jump\n",
    "Keep\n",
    "Kick\n",
    "Kiss\n",
    "Laugh\n",
    "Learn\n",
    "Leave\n",
    "Lend\n",
    "Lie\n",
    "Like\n",
    "Listen\n",
    "Lose\n",
    "Love\n",
    "Make\n",
    "Marry\n",
    "Measure\n",
    "Meet\n",
    "Move\n",
    "Murder\n",
    "Obey\n",
    "Offend\n",
    "Offer\n",
    "Open\n",
    "Paint\n",
    "Pay\n",
    "Pick\n",
    "Play\n",
    "Pray\n",
    "Print\n",
    "Pull\n",
    "Punch\n",
    "Punish\n",
    "Purchase\n",
    "Push\n",
    "Quit\n",
    "Race\n",
    "Read\n",
    "Relax\n",
    "Remember\n",
    "Reply\n",
    "Retire\n",
    "Rub\n",
    "See\n",
    "Select\n",
    "Sell\n",
    "Send\n",
    "Sing\n",
    "Snore\n",
    "Stand\n",
    "Stare\n",
    "Start\n",
    "Stink\n",
    "Study\n",
    "Sweep\n",
    "Swim\n",
    "Take\n",
    "Talk\n",
    "Teach\n",
    "Tear\n",
    "Tell\n",
    "Thank\n",
    "Travel\n",
    "Type\n",
    "Understand\n",
    "Use\n",
    "Visit\n",
    "Wait\n",
    "Walk\n",
    "Want\n",
    "Warn\n",
    "Wed\n",
    "Weep\n",
    "Wink\n",
    "Worry\n",
    "Write\n",
    "Yell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above list of verbs is not intended to be comprehensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <p>Note that you are not expected to use any actual algorithms or existing code/tools to perform this task. You are expected to approach the task naively and begin from scratch.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READING FROM A FILE\n",
    "\n",
    "Copy the above list of verbs into a file called `list_of_verbs.txt`. Save this file at the same location as `Assignment-2.ipynb`, then execute the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accept', 'Achieve', 'Add', 'Admire', 'Admit', 'Adopt', 'Advise', 'Agree', 'Allow', 'Announce', 'Appreciate', 'Approve', 'Argue', 'Arrive', 'Ask', 'Assist', 'Attack', 'Bake', 'Bathe', 'Be', 'Beat', 'Become', 'Beg', 'Behave', 'Bet', 'Boast', 'Boil', 'Borrow', 'Breathe', 'Bring', 'Build', 'Burn', 'Bury', 'bury', 'Buried', 'Burying', 'Buy', 'Call', 'Catch', 'Challenge', 'Change', 'Cheat', 'Chew', 'Choose', 'Clap', 'Clean', 'Collect', 'Compare', 'Complain', 'Confess', 'Confuse', 'Construct', 'Control', 'Copy', 'Count', 'Create', 'Cry', 'Damage', 'Dance', 'Deliver', 'Destroy', 'Disagree', 'Drag', 'Drive', 'Drop', 'Earn', 'Eat', 'Employ', 'Encourage', 'Enjoy', 'Establish', 'Estimate', 'Exercise', 'Expand', 'Explain', 'Fear', 'Feel', 'Fight', 'Find', 'Fly', 'Forget', 'Forgive', 'Fry', 'Gather', 'Get', 'Give', 'Glow', 'Greet', 'Grow', 'Guess', 'Harass', 'Hate', 'Hear', 'Help', 'Hit', 'Hope', 'Identify', 'Interrupt', 'Introduce', 'Irritate', 'Jump', 'Keep', 'Kick', 'Kiss', 'Laugh', 'Learn', 'Leave', 'Lend', 'Lie', 'Like', 'Listen', 'Lose', 'Love', 'Make', 'Marry', 'Measure', 'Meet', 'Move', 'Murder', 'Obey', 'Offend', 'Offer', 'Open', 'Paint', 'Pay', 'Pick', 'Play', 'Pray', 'Print', 'Pull', 'Punch', 'Punish', 'Purchase', 'Push', 'Quit', 'Race', 'Read', 'Relax', 'Remember', 'Reply', 'Retire', 'Rub', 'See', 'Select', 'Sell', 'Send', 'Sing', 'Snore', 'Stand', 'Stare', 'Start', 'Stink', 'Study', 'Sweep', 'Swim', 'Take', 'Talk', 'Teach', 'Tear', 'Tell', 'Thank', 'Travel', 'Type', 'Understand', 'Use', 'Visit', 'Wait', 'Walk', 'Want', 'Warn', 'Wed', 'Weep', 'Wink', 'Worry', 'Write', 'Yell']\n"
     ]
    }
   ],
   "source": [
    "def read_list_of_verbs_from_file():\n",
    "    verb_file = open('list_of_verbs.txt')\n",
    "    file_contents = verb_file.read()\n",
    "    verb_file.close()\n",
    "    return file_contents.split(\" \")\n",
    "\n",
    "list_of_verbs = read_list_of_verbs_from_file()\n",
    "\n",
    "# uncomment the next line to verify we have correctly read the file and parsed its contents into a list of verbs\n",
    "print(list_of_verbs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING A SET OF RULES\n",
    "\n",
    "Use **Table 4.2** (from https://www.nltk.org/book/ch01.html) to create some potential rules/characteriztics for identifying whether a word is a **verb**. For example, if the word ends in `ing` then it can be considered a verb. Another simple rule to implement is to see if the word is in our `list_of_verbs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word_a_verb(word):\n",
    "    if word.endswith('ing'):\n",
    "        condition1 = True\n",
    "    else:\n",
    "        condition1 = False\n",
    "    \n",
    "    condition2 = False\n",
    "    for s in list_of_verbs:\n",
    "        if word.startswith(s.lower()):\n",
    "            condition2 = True\n",
    "    \n",
    "    if word.endswith('ed'):\n",
    "        condition3 = True\n",
    "    else:\n",
    "        condition3 = False\n",
    "    \n",
    "    return condition1 or condition2 or condition3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA TO TEST PERFORMANCE OF CODE\n",
    "\n",
    "An example of what the test data could look like is the following list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = [\n",
    "    \"hat\",\n",
    "    \"run\",\n",
    "    \"sadness\",\n",
    "    \"crying\",\n",
    "    \"chew\",\n",
    "    \"kiss\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code will take one word at a time from the list and determine whether the word was a verb or not. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_word_a_verb(\"hat\")`\n",
    "\n",
    "would return `False`, whereas:\n",
    "\n",
    "`is_word_a_verb(\"crying\")`\n",
    "\n",
    "would return `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the list of words in `testing_data` are unrelated to each other, meaning they are not necessarily from the same sentence (or even the same document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATION\n",
    "\n",
    "Evaluate how well your code performs on the list of words in `testing_data`.\n",
    "\n",
    "Add your own set of words to `testing_data` to further evaluate how robust your code is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat False\n",
      "run False\n",
      "sadness False\n",
      "crying True\n",
      "chew True\n",
      "kiss True\n"
     ]
    }
   ],
   "source": [
    "for word in testing_data:\n",
    "    print(word, is_word_a_verb(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat False\n",
      "run False\n",
      "sadness False\n",
      "crying True\n",
      "chew True\n",
      "kiss True\n",
      "love True\n",
      "create True\n",
      "are False\n",
      "do False\n",
      "accepted True\n"
     ]
    }
   ],
   "source": [
    "# testing_data with own data\n",
    "testing_data = [\n",
    "    \"hat\",\n",
    "    \"run\",\n",
    "    \"sadness\",\n",
    "    \"crying\",\n",
    "    \"chew\",\n",
    "    \"kiss\",\n",
    "    \"love\",\n",
    "    \"create\",\n",
    "    \"are\",\n",
    "    \"do\",\n",
    "    \"accepted\"\n",
    "]\n",
    "\n",
    "for word in testing_data:\n",
    "    print(word, is_word_a_verb(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISCUSSION\n",
    "\n",
    "Briefly discuss the performance of your code (1-2 paragraphs).\n",
    "\n",
    "What types of verbs did the code perform well on? What types of verbs did it not perform well on?\n",
    "\n",
    "Are there any problems with this approach in identifying whether a word is a verb?\n",
    "\n",
    "Are there any issues with the list of verbs in our `list_of_verbs.txt` file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current performance of my code is not satisfactory, as it missed three out of ten verbs. While the code is able to identify verbs present in the provided list, as well as verbs ending in \"ing\" and \"ed\" which correspond to present and past tenses, it falls short in detecting verbs with irregular past tense forms, such as \"are\" and \"drove\". Additionally, any verbs that are not present in the list and do not follow the standard present and past tenses will not be identified by the code.\n",
    "\n",
    "The limitations of this approach are not surprising, given the inherent complexity of natural language processing. Verbs, in particular, have many different forms, including numerous irregular ones. An approach based solely on a pre-defined list of verbs like the list of verbs in our file is bound to miss many edge cases.\n",
    "\n",
    "To improve the accuracy of the verb identification algorithm, one possible solution is to incorporate more comprehensive verb lists or to use natural language processing libraries that offer part-of-speech tagging functionality. Another option is to explore machine learning techniques to train a model for identifying verbs in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>The best approach to this question is to work on <strong>one aspect at a time</strong>. Since one aspect is not going to identify all possible verbs, treat each aspect as a <em>step</em> toward a destination where improvements are likely small increments.</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#B6321C>\n",
    "    \n",
    "### RUBRIC\n",
    "\n",
    "<font color=black>\n",
    "\n",
    "We will be evaluating this section in part by your **ambition** in trying to capture difficult aspects of a verb, **not how well** you encoded the aspects of the verbs you were trying to capture.\\\n",
    "A breakdown of the marking for this task:\n",
    "* <font color=#B6321C>[**5 marks**]<font color=black> basic features gathered (trivial, used one or two builtin `NLTK`/`Python` methods in a simple way)\n",
    "* <font color=#B6321C>[**5 marks**]<font color=black> distinctly different aspects gathered (advanced), corresponding to aspects not exactly trivial to encode (tried using a few builtin `NLTK`/`Python` methods in a complex way)\n",
    "* <font color=#B6321C>[**5 marks**]<font color=black> discussion of results explaining the performance of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<font color=darkred>\n",
    "    \n",
    "# QUESTION: Identifying Proper Names In A Text Document\n",
    "    \n",
    "<font color=black>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"\"\"\n",
    "Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think\n",
    "that they can change the world, are the ones who do.\n",
    "The quote baove is by Steve Jobs. Mr. Jobs also said: I choose a lazy person to do a hard job. Because a lazy person will find an easy way to do it. Steve started the apple computer company with Steve Wozniak (aka `Woz'). Little known facts:\n",
    "Trump did not like Jobs. Jobs did not like Trump.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous question (\"*Creating Rules To Identify Verbs*\"), write code that automatically identifies all words/terms that are **proper names**. Use the sample text provided in `text_data` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <p>Note that you are not expected to use any actual algorithms or existing code/tools to perform this task. You are expected to approach the task naively and begin from scratch.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_name(text_data):\n",
    "    # tokenize the text data \n",
    "    paragraphs = text_data.split('\\n\\n')\n",
    "    \n",
    "    exclude = [\"I\", \"You\", \"They\", \"He\", \"She\", \"The\", \"Because\"]\n",
    "    \n",
    "    for paragraph in paragraphs:\n",
    "        # replace \\n with \" \"\n",
    "        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "    \n",
    "    text = \"\".join(paragraph)\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    while \"\" in words:\n",
    "        words.remove(\"\")\n",
    "    \n",
    "    names = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word[0].isupper():\n",
    "            potential_name = word\n",
    "        if i > 1:\n",
    "            if words[i-1][0].islower():\n",
    "                name = potential_name\n",
    "                if \".\" in name:\n",
    "                    name = name.replace(\".\", \"\")\n",
    "                    names.append(name)\n",
    "                    name = \"\"\n",
    "                    next\n",
    "                if i + 1 < len(words):\n",
    "                    if words[i+1][0].isupper() and name != \"\":\n",
    "                        name = name + \" \" + words[i+1]\n",
    "                if name != \"\" and name not in exclude:\n",
    "                    if \".\" in name:\n",
    "                        name = name.replace(\".\", \"\")\n",
    "                    names.append(name)\n",
    "        potential_name = \"\"\n",
    "        name = \"\"\n",
    "        \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Steve Jobs', 'Steve', 'Steve Wozniak', 'Trump', 'Jobs', 'Trump']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identify_name(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of **proper names** are:\n",
    "* John\n",
    "* Vancouver\n",
    "* Trudeau\n",
    "* Pierre Trudeau\n",
    "* British Columbia, Canada\n",
    "* Rememberance Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISCUSSION\n",
    "\n",
    "Briefly discuss the performance of your code (1-2 paragraphs).\n",
    "\n",
    "What types of proper names did the code perform well on? What types of proper names did it not perform well on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of this code is limited. The code identify names in a given text data by splitting the text into individual words. And then it iterates through each word in the text and checks if the first letter is uppercase. If the previous word is lowercase and the current word is uppercase, it considers this a complete name and adds it to a list of identified names. The code also removes empty words and excludes certain words from being considered names. The code will ne slow for longer texts. \n",
    "\n",
    "It perform well for names in the middle of the text with regular capitalization. However, it does not handle names have unusual captitalization and names at the begining of text. Also, it might mktatke non-names that happen to start with a capital letter as names in the middle of the text. \n",
    "\n",
    "We could imporve the performance by utilizing regular expressions, removing stopwords and etc,."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#B6321C>\n",
    "    \n",
    "### RUBRIC\n",
    "\n",
    "<font color=black>\n",
    "\n",
    "Again, we will be evaluating this section for your **ambition** in trying to capture different aspects of a proper name, **not how well** you coded the aspects of the proper names.\\\n",
    "A breakdown of the marking for this task:\n",
    "* <font color=#B6321C>[**5 marks**]<font color=black> basic features gathered (trivial, used one or two builtin `NLTK`/`Python` methods in a simple way)\n",
    "* <font color=#B6321C>[**5 marks**]<font color=black> distinctly different aspects gathered (advanced), corresponding to aspects not exactly trivial to encode (tried using a few builtin `NLTK`/`Python` methods in a complex way)\n",
    "* <font color=#B6321C>[**5 marks**]<font color=black> discussion of results explaining the performance of the code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
